# ðŸš€ Roadmap Phase 7: QualitÃ¤t, UX & Erweiterungen

> **Stand:** 2026-02-13 | **Status:** Weitgehend abgeschlossen
> **Ausgangslage:** Phase 6 stabil (ReAct Agent, 7 Tools, Multi-Tenant, File-Upload Protokoll)
> **Git-Tag Baseline:** `v2026.02.13-phase6-hotfix`
> **Aktueller Stand:** Auto-Discovery, Model-Management, Prompt-basiertes Tool-Calling, DeepSeek-R1 integriert

---

## 1. Was ist erledigt (Phase 1â€“6)

| Phase | Features | Status |
|-------|----------|--------|
| 1â€“3 | ES+Chroma Indexierung, Hybrid-Suche, RAG-Pipeline | âœ… |
| 4 | Python Code Execution (PyRunner Sandbox) | âœ… |
| 5 | Transcriptâ†’Protocol, Dynamic num_ctx/Timeout, OpenWebUI File-Upload | âœ… |
| 6 | ReAct Agent (7 Tools), Multi-Tenant, Forced-Step, Phase-Indikatoren | âœ… |
| Hotfixes | Title-Bypass, example.com URLs, File-Upload Context-Extraktion | âœ… |

---

## 2. Offene Punkte aus Phase 6

### 2.1 ~~Web-Suche (braucht API-Key)~~ âœ… Erledigt
- SearXNG als self-hosted Meta-Suchmaschine integriert (kein API-Key nÃ¶tig)
- Container: `searxng/searxng:latest`, Config: `searxng/settings.yml`
- Fallback-Kette: SearXNG â†’ Brave API â†’ Serper.dev
- Getestet unter `rag-llama4:latest` âœ…

### 2.2 ~~Fess-Plugins aus ES entfernen~~ âœ… Erledigt
- ES neu gebaut ohne Plugins (`docker compose build --no-cache elasticsearch`)
- 0 Plugins installiert, ES lÃ¤uft sauber (34 Shards, yellow/single-node)

### 2.3 Zweiter Mandant testen
- Tenant-System ist gebaut (`tenants/_template.yaml`), aber nur SBB TFK aktiv
- Zum Testen: Template kopieren, ausfÃ¼llen, Daten indexieren

---

## 3. Verbesserungskatalog (priorisiert)

### Prio 1: QualitÃ¤t & StabilitÃ¤t

#### 3.1 ~~AntwortqualitÃ¤t verbessern~~ âœ… Erledigt (System-Prompt)
- REACT_SYSTEM_PROMPT Ã¼berarbeitet: Indikativ statt Konjunktiv, exakte Zitate, Seitenzahlen
- Greeting-Fix: Keine Tool-Liste mehr bei "Hallo"
- Forced search â†’ read_document Hint: LLM bekommt Extra-Step um Dokumente vollstÃ¤ndig zu lesen
- **Offen:** Reranking (Cross-Encoder), Context-QualitÃ¤t (ganze AbsÃ¤tze)

#### 3.2 ~~Fehlertoleranz~~ âœ… Erledigt
- `LLMError` Exception + Retry-Logik (1x Retry, +60s Timeout)
- `_llm_with_tools` und `_llm_stream_final`: Retry bei ReadTimeout, ConnectTimeout, ConnectError
- User-freundliche Fehlermeldung mit Tipps (Modell wechseln, erneut versuchen)

#### 3.2b ~~Modell-Architektur~~ âœ… Erledigt
- **Auto-Discovery**: `REACT_MODELS` Whitelist entfernt â€“ ALLE Modelle gehen durch ReAct Agent
- **Kein `rag-` Prefix mehr**: Modelle erscheinen unter ihrem echten Ollama-Namen
- **Ollama Proxy**: agent_api proxied `/api/tags`, `/api/pull`, `/api/delete`, `/api/show`, `/api/chat`
- **OpenWebUI Single-Connection**: Nur noch Ã¼ber agent_api (kein direktes Ollama mehr)
- **Modell-Management via UI**: Neue Modelle pullen/lÃ¶schen direkt in OpenWebUI
- **Embedding-Schutz**: `mxbai-embed-large` kann nicht gelÃ¶scht werden (technisch nÃ¶tig fÃ¼r Vektorsuche)
- **AufgerÃ¤umte Modelle**: qwen2.5:72b, qwen2.5:14b, llama3.1 entfernt (~100 GB frei)
- **Aktiver Kern**: llama4 (67GB), deepseek-r1:70b (42GB), gpt-oss (13GB), qwen2.5:3b (1.9GB), apertus:70b (43GB)
- **Prompt-basiertes Tool-Calling**: Reasoning-Modelle (DeepSeek-R1, QwQ, etc.) ohne native Tool-API werden automatisch erkannt und nutzen Prompt-basierten Fallback mit `<tool_call>` Tags
- **Greeting-Shortcut**: Prompt-Tool-Modelle Ã¼berspringen den teuren Tool-Prompt bei einfachen Fragen
- **Timeouts**: Reasoning-Modelle erhalten 600s statt 300s (lange `<think>`-Phase)

#### 3.3 Indexer-Verbesserungen
- **Inkrementelles Re-Indexing**: Nur geÃ¤nderte Dateien neu indexieren (Manifest existiert)
- **Neue Formate**: HTML, RTF, CSV nativ (nicht nur via Python)
- **Metadaten-Extraktion**: Autor, Datum, Betreff aus E-Mails und Office-Dokumenten

### Prio 2: UX-Verbesserungen

#### 3.4 Bessere Quellen-Links
- Quellen als klickbare Links die das Dokument direkt Ã¶ffnen
- PDF: Direkt zur Seite springen (wenn Seitennummer bekannt)
- Quellen-Preview: Kurzes Snippet unter jedem Link

#### 3.5 Chat-Kontext verbessern
- LÃ¤ngerer Konversationsverlauf (aktuell 3 Turns)
- Session-Zusammenfassung fÃ¼r lange GesprÃ¤che
- "Merke dir X" â†’ Persistenter Notiz-Speicher pro Mandant

#### 3.6 Fortschrittsanzeige
- Bessere Phase-Indikatoren: "Schritt 2/4: Lese Dokument..."
- GeschÃ¤tzte Wartezeit bei langen Operationen
- Token-ZÃ¤hler / Context-Window-Auslastung (fÃ¼r Debugging)

### Prio 3: Neue Features

#### 3.7 Dokumenten-Vergleich
- Automatischer Diff/Vergleich zweier Dokumente
- Ã„nderungstracking zwischen VersionsstÃ¤nden
- "Was hat sich zwischen Version 1 und 2 des Werkvertrags geÃ¤ndert?"

#### 3.8 Zusammenfassungs-Modus
- Ganzes Dokument zusammenfassen (nicht nur Suchtreffer-Snippets)
- Mehrseitige PDFs kapitelweise zusammenfassen
- Executive Summary fÃ¼r Vertragsdokumente

#### 3.9 Automatische Reports
- "Erstelle einen Statusbericht Ã¼ber alle offenen Pendenzen"
- Aggregation Ã¼ber mehrere Dokumente
- Export als Markdown oder PDF

#### 3.10 Whisper-Integration
- Direkte Audio-Upload â†’ Transkription â†’ Protokoll
- Whisper lokal auf DGX Spark (GPU verfÃ¼gbar)
- Speaker Diarization fÃ¼r automatische Sprecher-Erkennung

### Prio 4: Infrastruktur

#### 3.11 Monitoring & Logging
- Strukturiertes Logging (JSON) statt Print-Statements
- Request-Tracing (Request-ID durch alle Services)
- Metriken: Antwortzeit, Token-Verbrauch, Tool-Nutzung

#### 3.12 Backup & Recovery
- ES-Snapshots automatisiert
- ChromaDB-Backup
- State-Backup

#### 3.13 Security
- API-Key-Authentifizierung (aktuell offen)
- Rate-Limiting
- Audit-Log (wer hat was gefragt)

---

## 4. Empfohlene Reihenfolge (aktualisiert 2026-02-13)

### âœ… Erledigt (Phase 7)
1. ~~Web-Search~~ â†’ SearXNG self-hosted âœ…
2. ~~ES ohne Fess-Plugins~~ âœ…
3. ~~AntwortqualitÃ¤t: System-Prompt Tuning~~ âœ…
4. ~~Fehlertoleranz: Retry + Fehlermeldungen~~ âœ…
5. ~~Modell-Architektur: Auto-Discovery, kein rag- Prefix~~ âœ…
6. ~~DeepSeek-R1: Prompt-basiertes Tool-Calling~~ âœ…

### NÃ¤chste Session (Phase 8a â€“ Retrieval-QualitÃ¤t)
7. **Cross-Encoder Reranking** â†’ deutlich bessere Suchergebnisse (1 GB GPU)
8. **Indexer: Metadaten-Extraktion** â†’ Autor, Datum, Betreff aus E-Mails/Office
9. **Quellen-Links verbessern** â†’ klickbare Links, PDF-Seitensprung

### Mittelfristig (Phase 8b â€“ Autonomie)
10. **Whisper-Integration** â†’ Audio-Upload â†’ Transkription â†’ Protokoll (lokal auf GPU)
11. **Langzeit-GedÃ¤chtnis** â†’ Persistenter Notiz-Speicher pro Mandant/Session
12. **Multi-Dokument-Vergleich** â†’ Diff zwischen Versionen, Ã„nderungstracking
13. **Zusammenfassungs-Modus** â†’ Ganzes Dokument kapitelweise zusammenfassen

### Langfristig (Phase 9 â€“ Produktionsreife)
14. Monitoring & strukturiertes Logging (JSON, Request-Tracing)
15. Security (API-Keys, Rate-Limiting, Audit-Log)
16. Automatische Reports (Statusberichte, Export als PDF)
17. Zweiter Mandant aufsetzen + testen

---

## 5. Hardware-Potential (DGX Spark)

Die NVIDIA DGX Spark hat 128GB unified RAM (CPU+GPU shared). Aktuell genutzt:
- Ollama: ~125GB auf Disk (llama4:67GB, deepseek-r1:42GB, gpt-oss:13GB, qwen2.5:3b, apertus:43GB, mxbai-embed)
- ES: ~2GB RAM
- ChromaDB + Services: ~4GB RAM
- **Hinweis**: Nicht alle Modelle gleichzeitig im VRAM â€“ Ollama lÃ¤dt/entlÃ¤dt automatisch

MÃ¶glichkeiten:
- **Whisper Large V3**: ~3GB GPU RAM â†’ lokale Transkription
- **Cross-Encoder Reranking**: ~1GB â†’ bessere Suchergebnisse
- **Hinweis zu DeepSeek-R1:70b**: Reasoning-Modell mit `<think>`-Phase, ~3 Min/Step, ideal fÃ¼r komplexe Analysen aber langsam

---

## 6. ðŸ”® Vision: Ausbaustufen zum Autonomen Agent-System

### Stufe 1: Intelligenter Assistent (âœ… AKTUELL)
> *"Frag mich was Ã¼ber deine Dokumente"*
- ReAct Agent mit 7 Tools, autonome Recherche
- Hybrid-Suche (ES + ChromaDB), Code-Execution, Web-Suche
- Prompt-basiertes Tool-Calling fÃ¼r alle Modelltypen

### Stufe 2: Proaktiver Analyst
> *"Ich erkenne Muster und mache VorschlÃ¤ge"*
- **Cross-Encoder Reranking**: Deutlich bessere TrefferqualitÃ¤t
- **Zusammenfassungen on-demand**: Ganzes Dokument â†’ Executive Summary
- **Dokumenten-Vergleich**: "Was hat sich geÃ¤ndert zwischen V1 und V2?"
- **Automatische Klassifikation**: Neue Dokumente werden beim Indexieren kategorisiert
- **Follow-up-VorschlÃ¤ge**: Agent schlÃ¤gt nach Antwort relevante Folgefragen vor

### Stufe 3: Kollaborativer Wissensarbeiter
> *"Ich merke mir was du brauchst und arbeite Ã¼ber Sessions hinweg"*
- **Langzeit-GedÃ¤chtnis**: Persistenter Speicher pro User/Mandant (wichtige Fakten, PrÃ¤ferenzen)
- **Whisper-Pipeline**: Audio â†’ Transkription â†’ Protokoll â†’ Pendenzenliste (End-to-End)
- **Multi-Step-Planung**: Komplexe Aufgaben in Teilschritte zerlegen mit Checkpoints
- **Report-Generator**: Automatische Statusberichte Ã¼ber mehrere Dokumente/Themen
- **Benachrichtigungen**: "Neues Dokument indexiert das zu deiner letzten Frage passt"

### Stufe 4: Autonomer Projektassistent
> *"Ich Ã¼berwache, analysiere und handle proaktiv"*
- **Scheduled Tasks**: RegelmÃ¤ssige Reports, Ã„nderungs-Monitoring
- **Multi-Agent-Architektur**: Spezialisierte Sub-Agenten (Recherche, Analyse, Redaktion)
- **Workflow-Automation**: Ketten von Aktionen (Index â†’ Analyse â†’ Report â†’ Versand)
- **Versionierte Wissensbasis**: Ã„nderungshistorie, Rollback, Diff
- **API-Schnittstelle**: Externe Systeme kÃ¶nnen den Agent ansprechen (Webhook, REST)
